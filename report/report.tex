\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{verbatim}\usepackage{url}
\usepackage{natbib}
\usepackage[labelformat=simple]{subcaption}
\renewcommand\thesubfigure{(\alph{subfigure})}
\usepackage{pgfplots, graphicx, amsmath,amsthm,amssymb,mathtools,   natbib,tikz}
\usetikzlibrary{arrows.meta, shadows, arrows, positioning}
\usepackage{color}
\definecolor{SFUred} {RGB}{131,33,37}
\title{A Neural Network Approach to Classifying Banana Ripeness}

\author{
Kyle Demeule\\
Department of Computing Science\\
Faculty of Applied Sciences\\
Simon Fraser University\\
8888 University Drive\\
\texttt{kdd2@sfu.ca} \\
\And
Bernard S Chan \\
Department of Computing Science\\
Faculty of Applied Sciences\\
Simon Fraser University\\
8888 University Drive\\
\texttt{bernardc@sfu.ca} \\
\AND
Saeed Soltani\\
Department of Computing Science\\Faculty of Applied Sciences\\
Simon Fraser University\\
8888 University Drive\\
\texttt{saeeds@sfu.ca} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
In this paper, a new technique to detect the banana and its ripeness is introduced. This paper includes the methods and experiments that were implemented in the project. Some of the techniques that were used in this project includes classifying images by support vector machines in linear, radial basis functions and sigmoid functions. Also, we explain the optimization methods that used to improve the accuracy and decrease the number of features.\end{abstract}

\section{Introduction}

Traditionally, humans detect ripeness of fruit  through sight, odour, taste and touch. While people and animals are naturally equipped with these senses, machines are not, so automating fruit ripeness detection is a difficult task. Given that odor sensors and image processing are more reliable and developed than taste and touch, machine learning research in detecting fruit ripeness have been based around odor and and sight.  Through different type of odour sensors,~\citet{llobet1999non} and~\citet{li2007neural} collected smell information on ripening bananas and apples. Then, they applied various supervised classifier to classify their states.

Instead of odour, we are interested in integrating imaging and deep learning techniques to classify the ripeness of bananas. Based on reviews by~\citet{dadwal2012color} and~\citet{kodagali2012computer}, typical computer vision based ripeness detection methods are based on histogram matching or image segmentation. For example,~\citet{paulraj2009color} proposed a histogram-based neural network classifier for evaluating ripeness banana He derived that by using the histograms that were obtained from banana pictures as a feature vector and sending that as an input to neural networks, it could classify the imported banana as ripe or unripe. 

The ripeness recognition rate for his algorithm is 96\%. However, this model does not distinguish the non-banana from banana and would only predict the ripeness. In this project, our aim was to implement a new method that could firstly detect whether the imported picture contains any banana and secondly detect the ripeness of banana based on the its skin color. Our approach to this issue is to perform feature extraction of images by using convolutional neural networks and constructing support vector machine classification model that could classify an object by detecting whether it is banana or non-banana and recognize the ripeness, if it is a banana. This model could be very helpful in helping disabled people to detect the ripeness of bananas. In addition, it could become handy in industry for large scale sorting. 
\section {Background}
\begin{itemize}
\item literuatre review on fruit ripeness
\item literature review on neural network, deep learning, AlexNet
\item introduction to technolgies used (Caffe, ScikitLearn)
\end{itemize}
\section{Methodology}
For this project, we created our own data set on banana and non-banana objects because the previous data sets from~\citet{saad2009recognizing} and~\citet{paulraj2009color} were not available. After establishing our own data set, we extracted the features of the images using a pre-trained convolution neural network. The Caffe deep learning frame work by~\citet{jia2014caffe} allowed us to access from many existing models. Given that we have a visualization task with different types of objects, we chose AlexNet by~\citet{krizhevsky2012imagenet} to extract the features. After obtaining the features of the images, we used the SVM library provided in SciKit Learn~\citep{scikit-learn} to classify the objects. A workflow of this project is shown as a flowchart in Figure~\ref{fig:flowchart}. In this section, we will discuss the details in each step of our work. 

\tikzstyle{block} = [rectangle, draw, fill=SFUred!20, 
    text width=30em, text centered, rounded corners, minimum height=2em]
    \tikzstyle{small} = [rectangle, draw, fill=white!20, 
    text width=5em, text centered, rounded corners, minimum height=2em]
        \tikzstyle{medium} = [rectangle, draw, fill=white!20, 
    text width=8em, text centered, rounded corners, minimum height=2em]

\tikzstyle{line} = [draw, -latex']

\begin{figure} [h]
\centering 
{
\begin{tikzpicture}[node distance = 1.2cm, auto,scale=.1]
    % Place nodes
    \node [block] (capture) {Capture images};
    \node [block, below of=capture] (process) {Label and process images (crop, resize and convert to RGB)};
%    \node [block, below of=process] (convert) {Convert to RGB };
    \node [block, below of= process] (cnn) {Extract features via CNN (Caffe and AlexNet)};
    \node [block, below of=cnn] (svm) {Classify data via SVM (SciKit Learn)};
    \node [medium, below left = 1cm and -10cm of svm] (nonbanana) {Non-Banana};
    \node [small, below right = 1.cm and -10 cm of svm] (banana) {Banana};
    \node [small, below of = banana] (ripe) {Ripe};
    \node [small, below left = . cm and .9 cm of banana] (unripe) {Unripe};
     \node [small, below right = .cm and .9 cm of banana] (overripe) {Overripe};

    % Draw edges
    \path [line] (capture) -- (process);
    \path [line] (process) -- (cnn);
%    \path [line] (convert)--(cnn);
    \path [line] (cnn)--(svm);
    \path [line] (svm)--(nonbanana);
        \path [line] (svm)--(banana);
          \path [line] (banana)--(unripe);
        \path [line] (banana)--(overripe);
	\path [line] (banana)--(ripe);
\end{tikzpicture}
}
\caption{A flow chart of project development.}
\label{fig:flowchart}
 \end{figure}


\subsection{Generating and Preparing the Data set}

Since the data sets used by~\citet{saad2009recognizing} and~\citet{paulraj2009color} were not publicly available, we decided to create on our own data set. Controlling for lighting, background and camera (Canon S90), we took pictures of banana and various non-banana objects. After the pictures were taken, we incorporated each picture at $0\,^{\circ}$, $90\,^{\circ}$, $180\,^{\circ}$ and  $270\,^{\circ}$ of rotation to increase the number of pictures in the data set by four fold. Also, there were equal number of pictures for each of the four labels: unripe banana, ripe banana, overripe banana and non-banana. For the banana data set, twelve unique bananas were used. We used apples, tomatos, lemons, limes, mushrooms, broccolis, potatos, pears and green peppers as non-banana objects. In total, there were 928 images generated for the data set and sample pictures of this data set are shown in Figure~\ref{fig:sampleDataset}. After obtaining the data set, we used various Python scripts to standardize the images so that each one is resized and cropped to $256\times 256$ pixels. Furthermore, each picture is decomposed into the RGB channels for features extraction. 

\begin{figure}[h]
 %%%%%% unripe %%%%%%%%%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{1_1.jpg}
\end{subfigure}%
 \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{1_2.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{1_3.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{1_4.jpg}
\end{subfigure}\, %%%%%% ripe %%%%%%%%%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{2_1.jpg}
\end{subfigure}%
 \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{2_2.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{2_3.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{2_4.jpg}
\end{subfigure}%
\vskip .05in
 %%%%%% overripe %%%%%%%%%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{0_1.jpg}
\end{subfigure}%
 \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{0_2.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{0_3.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{0_4.jpg}
\end{subfigure}\,
 %%%%%% non banana %%%%%%%%%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{3_1.jpg}
\end{subfigure}%
 \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{3_5.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{3_17.jpg}
\end{subfigure}%
  \begin{subfigure}{.123\textwidth}
  \centering
\includegraphics[width=\textwidth]{3_13.jpg}
\end{subfigure}%
\caption{Upper left: unripe bananas. Upper right: ripe bananas. Lower left: overripe bananas. Lower Right: non-banana objects.}
\label{fig:sampleDataset}
\end{figure}

 
\subsection{Features Extraction via AlexNet}
\begin{itemize}
  \item Caffe~\citep{jia2014caffe}: deep learning framework for using AlexNet. 
\item AlexNet: five convolutional layers and three fully connected layers.

 \item AlexNet~\citep{krizhevsky2012imagenet}: a pre-trained CNN for features extraction.

\item Originally trained to classify images for the ILSVRC-2012 challenge. 
\item Extract representation of data set from last three layers (FC6, FC7 and FC8). 
\item Internal representations at these layers are vectors of length 4096 (FC6, FC7) or 1000 (FC8). 
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{alexnet.png}
\caption{Architechture of AlexNet.}
\label{fig:alexnet}
\end{figure}

\subsection{Classification}
 \begin{itemize}
  \item Each set of four rotated pictures were either in the train or test set. 
  \item SciKit Learn~\citep{scikit-learn}: a Python library of machine learning algorithms. 
 \begin{itemize}
 \item Applied C-Support Vector Classification (\emph{sklenar.svm.svc}) to the extracted features for classification. 
 \item Linear, RBF, sigmoid and polynomial kernels were compared. 
 \item Parameters optimization through exhaustive grid search (\emph{sklearn.grid\_search}).
 \end{itemize}
 \end{itemize}
 
 \section{Results}
\begin{itemize}
\item Tested various kernel methods from SciKit Learn's SVM library.
\item Experimental results are shown in Tables~\ref{tab:core} and~\ref{tab:banana}
\end{itemize}
\begin{table}[h]
\caption{Overall percentage of correctly classified objects from training and testing of SVM models with various kernels. Features were obtained from FC6, FC7 and FC8 exits of AlexNet. (Lin = linear, RBF = radial basis function, Sig = sigmoid, Poly = polynomial)}
\label{tab:core}
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}\hline
 &  \multicolumn{4}{c|}{Training Results} & \multicolumn{4}{c|}{Testing Results}\\\hline
&Lin& RBF&Sig&Poly&Lin& RBF&Sig&Poly\\\hline
FC6&0.942&1.000&0.266&0.911&0.821&0.878&0.218&0.814\\\hline
FC7&0.876&1.000&0.266&0.872&0.788&0.862&0.218&0.804\\\hline
FC8&0.768&0.998&0.266&0.807&0.676&0.843&0.278&0.696\\\hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Percentage of objects correctly classified based on banana, ripeness and non-banana objects. Features were obtained from FC6, FC7 and FC8 exits of AlexNet. (Lin = linear, RBF = radial basis function, Sig = sigmoid, Poly = polynomial)}
\label{tab:banana}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}\hline
 &  \multicolumn{4}{c|}{Banana as Banana} & \multicolumn{4}{c|}{Ripeness}& \multicolumn{4}{c|}{Object as Object}\\\hline
&Lin& RBF&Sig&Poly&Lin& RBF&Sig&Poly&Lin& RBF&Sig&Poly\\\hline
FC6&0.946&0.953&1.000&0.958&0.862&0.902&0.288&0.885&0.829&0.934&0.000&0.711\\\hline
FC7&0.924&0.945&1.000&0.932&0.885&0.901&0.288&0.895&0.697&0.882&0.000&0.711\\\hline
FC8&0.864&0.924&1.000&0.877&0.804&0.890&0.2880&0.826&0.618&0.908&0.000&0.605\\\hline
\end{tabular}
\end{table}

\begin{itemize}
\item (RBF, FC6)  outperformed all other classifiers with 100.0\% accuracy in training and 87.8\% accuracy in testing.
\item (RBF, FC6) improved the performance of~\citet{saad2009recognizing} in classifying banana ripeness with significantly larger data set.
\item Sigmoid kernel classified every object as banana; 100\% accuracy in classifying banana but 100\% error on all non-banana objects.
\end{itemize}
\section{Conclusion and Future Work}
\begin{itemize}
\item Successfully enhanced previous work by adding non-banana objects. 
\item Future: generalize ripeness detection to other fruits and vegetables. 
\item Industrial application: automatic large scale sorting. 
\item Mobile app for visually disabled: find the ripeness of fruits and vegetables via phone camera. 
\item Code and data set available at \href{bit.ly/BananaRipe}{bit.ly/BananaRipe}
\end{itemize}

\subsubsection*{Acknowledgments}
We thank our TA Zhiwei (Lucas) Deng for his guidance on using Caffe as well as AlexNet and Dr. Mori for his insights on solving this problem. 
 
\renewcommand\refname{\vskip -.75cm}
\subsubsection*{References}

   \bibliography{report}		    
   \bibliographystyle{plainnat}
\end{document}
